{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google IT Automation with Python Professional Certificate\n",
    "## Course 4 Troubleshooting and Debugging Techniques - Final Exam\n",
    "\n",
    "\n",
    "\n",
    "### The task assigned for the final exam is as follows:\n",
    "\n",
    "## Improve performance\n",
    "Once you debug the issue, the program will start processing the file but it takes a long time to complete. This is because the program goes slowly line by line instead of printing the report quickly. You need to debug why the program is slow and then fix it. In this section, you need to find bottlenecks, improve the code, and make it finish faster.\n",
    "\n",
    "The problem with the script is that it’s downloading the whole file and then going over it for each date. The current script takes almost 2 minutes to complete for 2019-01-01. An optimized script should generate reports for the same date within a few seconds.\n",
    "\n",
    "To check the execution time of a script, add a prefix \"time\" and run the script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "42.9 s ± 26.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import csv\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "FILE_URL=\"http://marga.com.ar/employees-with-date.csv\"\n",
    "\n",
    "def get_start_date():\n",
    "    \"\"\"Interactively get the start date to query for.\"\"\"\n",
    "\n",
    "    print()\n",
    "    print('Getting the first start date to query for.')\n",
    "    print()\n",
    "    print('The date must be greater than Jan 1st, 2018')\n",
    "    year = 2020 #Commenting this out to run time for comparison int(input('Enter a value for the year: '))\n",
    "    month = 3 #Commenting this out to run time for comparison int(input('Enter a value for the month: '))\n",
    "    day = 20 #Commenting this out to run time for comparison int(input('Enter a value for the day: '))\n",
    "    print()\n",
    "\n",
    "    return datetime.datetime(year, month, day)\n",
    "\n",
    "def get_file_lines(url):\n",
    "    \"\"\"Returns the lines contained in the file at the given URL\"\"\"\n",
    "\n",
    "    # Download the file over the internet\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Decode all lines into strings\n",
    "    lines = []\n",
    "    for line in response.iter_lines():\n",
    "        lines.append(line.decode(\"UTF-8\"))\n",
    "    return lines\n",
    "\n",
    "def get_same_or_newer(start_date):\n",
    "    \"\"\"Returns the employees that started on the given date, or the closest one.\"\"\"\n",
    "    data = get_file_lines(FILE_URL)\n",
    "    reader = csv.reader(data[1:])\n",
    "\n",
    "    # We want all employees that started at the same date or the closest newer\n",
    "    # date. To calculate that, we go through all the data and find the\n",
    "    # employees that started on the smallest date that's equal or bigger than\n",
    "    # the given start date.\n",
    "    min_date = datetime.datetime.today()\n",
    "    min_date_employees = []\n",
    "    for row in reader:\n",
    "        row_date = datetime.datetime.strptime(row[3], '%Y-%m-%d')\n",
    "\n",
    "        # If this date is smaller than the one we're looking for,\n",
    "        # we skip this row\n",
    "        if row_date < start_date:\n",
    "            continue\n",
    "\n",
    "        # If this date is smaller than the current minimum,\n",
    "        # we pick it as the new minimum, resetting the list of\n",
    "        # employees at the minimal date.\n",
    "        if row_date < min_date:\n",
    "            min_date = row_date\n",
    "            min_date_employees = []\n",
    "\n",
    "        # If this date is the same as the current minimum,\n",
    "        # we add the employee in this row to the list of\n",
    "        # employees at the minimal date.\n",
    "        if row_date == min_date:\n",
    "            min_date_employees.append(\"{} {}\".format(row[0], row[1]))\n",
    "\n",
    "    return min_date, min_date_employees\n",
    "\n",
    "def list_newer(start_date):\n",
    "    while start_date < datetime.datetime.today():\n",
    "        start_date, employees = get_same_or_newer(start_date)\n",
    "        print(\"Started on {}: {}\".format(start_date.strftime(\"%b %d, %Y\"), employees))\n",
    "\n",
    "        # Now move the date to the next one\n",
    "        start_date = start_date + datetime.timedelta(days=1)\n",
    "\n",
    "def main():\n",
    "    start_date = get_start_date()\n",
    "    list_newer(start_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "By commenting out the user input and setting the date as a static variable in order to run this uninterrupted, we see the average run time is 42.9 s ± 26.2 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) for the input of March 20, 2020.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Improvment\n",
    "One thing we can do to improve the performance of this script is change it so that it is not downloading the whole file and then going over it for each date after our start date of March 20, 2020.  To do this, we change the get_same_or_newer function to accept the data parameter which was previously a variable set inside the function.  Then we put the data variable, data = get_file_lines(FILE_URL), into the list_newer function.  This way, each time the get_same_or_newer function is called inside of the list_newer function, we aren’t making a call to the site and downloading the information each iteration.  Inside the list_newer function, we also need to make sure we pass the data variable as a parameter to the get_same_or_newer inside the while loop of the list_newer function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "\n",
      "Getting the first start date to query for.\n",
      "\n",
      "The date must be greater than Jan 1st, 2018\n",
      "\n",
      "Started on Mar 24, 2020: ['Fiona Montoya', 'Kay Pratt']\n",
      "Started on Mar 27, 2020: ['Tate Chang']\n",
      "21.5 s ± 39.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import csv\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "FILE_URL=\"http://marga.com.ar/employees-with-date.csv\"\n",
    "\n",
    "def get_start_date():\n",
    "    \"\"\"Interactively get the start date to query for.\"\"\"\n",
    "\n",
    "    print()\n",
    "    print('Getting the first start date to query for.')\n",
    "    print()\n",
    "    print('The date must be greater than Jan 1st, 2018')\n",
    "    year = 2020 #Commenting this out to run time for comparison int(input('Enter a value for the year: '))\n",
    "    month = 3 #Commenting this out to run time for comparison int(input('Enter a value for the month: '))\n",
    "    day = 20 #Commenting this out to run time for comparison int(input('Enter a value for the day: '))\n",
    "    print()\n",
    "\n",
    "    return datetime.datetime(year, month, day)\n",
    "\n",
    "def get_file_lines(url):\n",
    "    \"\"\"Returns the lines contained in the file at the given URL\"\"\"\n",
    "\n",
    "    # Download the file over the internet\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Decode all lines into strings\n",
    "    lines = []\n",
    "    for line in response.iter_lines():\n",
    "        lines.append(line.decode(\"UTF-8\"))\n",
    "    return lines\n",
    "\n",
    "def get_same_or_newer(start_date, data):\n",
    "    \"\"\"Returns the employees that started on the given date, or the closest one.\"\"\"\n",
    "    \n",
    "    reader = csv.reader(data[1:])\n",
    "\n",
    "    # We want all employees that started at the same date or the closest newer\n",
    "    # date. To calculate that, we go through all the data and find the\n",
    "    # employees that started on the smallest date that's equal or bigger than\n",
    "    # the given start date.\n",
    "    min_date = datetime.datetime.today()\n",
    "    min_date_employees = []\n",
    "    for row in reader:\n",
    "        row_date = datetime.datetime.strptime(row[3], '%Y-%m-%d')\n",
    "\n",
    "        # If this date is smaller than the one we're looking for,\n",
    "        # we skip this row\n",
    "        if row_date < start_date:\n",
    "            continue\n",
    "\n",
    "        # If this date is smaller than the current minimum,\n",
    "        # we pick it as the new minimum, resetting the list of\n",
    "        # employees at the minimal date.\n",
    "        if row_date < min_date:\n",
    "            min_date = row_date\n",
    "            min_date_employees = []\n",
    "\n",
    "        # If this date is the same as the current minimum,\n",
    "        # we add the employee in this row to the list of\n",
    "        # employees at the minimal date.\n",
    "        if row_date == min_date:\n",
    "            min_date_employees.append(\"{} {}\".format(row[0], row[1]))\n",
    "\n",
    "    return min_date, min_date_employees\n",
    "\n",
    "def list_newer(start_date):\n",
    "    data = get_file_lines(FILE_URL)\n",
    "    while start_date < datetime.datetime.today():\n",
    "        start_date, employees = get_same_or_newer(start_date, data)\n",
    "        print(\"Started on {}: {}\".format(start_date.strftime(\"%b %d, %Y\"), employees))\n",
    "\n",
    "        # Now move the date to the next one\n",
    "        start_date = start_date + datetime.timedelta(days=1)\n",
    "\n",
    "def main():\n",
    "    start_date = get_start_date()\n",
    "    list_newer(start_date)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "By commenting out the user input and setting the date as a static variable in order to run this uninterrupted, we see the average run time is 21.5 s ± 39.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) for the input of March 20, 2020. \n",
    "\n",
    "#### This is a 21.4 second increase over the previous script.  \n",
    "I was curious if further optimization efforts were necessary or worth the time to implement.  I had a feeling the portion of the script that took the longest time to execute was the call to get the information from the url so I did another test to see how long this request took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.4 s ± 6.79 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "import csv\n",
    "import datetime\n",
    "import requests\n",
    "\n",
    "FILE_URL=\"http://marga.com.ar/employees-with-date.csv\"\n",
    "\n",
    "def get_file_lines(url):\n",
    "    \"\"\"Returns the lines contained in the file at the given URL\"\"\"\n",
    "\n",
    "    # Download the file over the internet\n",
    "    response = requests.get(url, stream=True)\n",
    "\n",
    "    # Decode all lines into strings\n",
    "    lines = []\n",
    "    for line in response.iter_lines():\n",
    "        lines.append(line.decode(\"UTF-8\"))\n",
    "    return lines\n",
    "\n",
    "get_file_lines(FILE_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "We see the average run time for simply calling the get_file_lines is 21.4 s ± 6.79 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
    "\n",
    "Given this is only a 0.10 second difference from our optimized script, and that I do not foresee this code being run more often than a maximum of once a day, I chose not to spend any further time optimizing the code.  Likely, the time taken to further optimize the code would be far greater than any further optimization would warrant given my assumption this would be run once a day at most."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
